---
title: Opencv Face Detect
description: 
date: 2022-03-01T16:00:00.000+00:00
duration: 30min
---

> åœ¨æµè§ˆå™¨ç«¯å®ç°äººè„¸è¯†åˆ«

å…ˆä¸Š<a href="/faceDetect/index.html" target="_blank">äººè„¸è¯†åˆ«Demo</a>

ä¸ºäº†å®ç°æµè§ˆå™¨ç«¯çš„äººè„¸è¯†åˆ«ï¼Œæˆ‘ä»¬å…ˆå¼•å…¥OpenCVå·¥å…·åº“

å®ƒæœ‰ä»€ä¹ˆä½œç”¨å‘¢ å…ˆç»™å¤§å®¶ç®€å•ä»‹ç»ä¸€ä¸‹â€”â€”

1. OpenCV æ˜¯ä¸€ä¸ªå¼€æºè·¨å¹³å°è®¡ç®—æœºè§†è§‰åº“å’Œæœºå™¨å­¦ä¹ è½¯ä»¶åº“ï¼Œ
2. ç”±Cå‡½æ•°å’Œå°‘é‡C++ç±»æ„æˆï¼Œæä¾›äº†å¤šä¸ªè¯­è¨€ï¼ˆPythonï¼ŒRubyï¼ŒMATLABç­‰ï¼‰çš„æ¥å£ã€‚
3. OpenCVæä¾›äº†å¤§é‡å›¾åƒå¤„ç†çš„åŠŸèƒ½ï¼Œä»å›¾åƒæ˜¾ç¤ºï¼Œåˆ°åƒç´ æ“ä½œï¼Œåˆ°ç›®æ ‡æ£€æµ‹ç­‰ï¼Œå¤§å¤§ç®€åŒ–äº†å›¾å½¢å¤„ç†ä»¥åŠæ·±åº¦å­¦ä¹ åº”ç”¨çš„å¼€å‘è¿‡ç¨‹ã€‚

ç”±äºå®ƒæ˜¯Cå¼€å‘çš„ï¼Œæ‰€ä»¥éœ€è¦ç¼–è¯‘åæ‰èƒ½åœ¨æµè§ˆå™¨ä¸­ä½¿ç”¨ã€‚è¿™é‡Œæˆ‘ä»¬ç›´æ¥ä»

[OpenCV.jså®˜æ–¹æ–‡æ¡£](https://docs.opencv.org/4.5.1/d5/d10/tutorial_js_root.html) ä¸­å–å¾—ç¼–è¯‘å®Œæˆçš„ 4.5.1 ç‰ˆæœ¬ [OpenCV.js](https://docs.opencv.org/4.5.1/opencv.js)



## åŸºæœ¬æµç¨‹

1. è¾“å…¥å›¾ç‰‡
2. è½¬ä¸ºOpenCV çŸ©é˜µæ ¼å¼å‚¨å­˜
3. ç»“åˆäººè„¸æ¨¡å‹è¿›è¡Œè¯†åˆ«äººè„¸ä½ç½®
4. ç»˜åˆ¶ç»“æœ

>  å…¶ä¸­ç¬¬3æ­¥ æ¨¡å‹æ˜¯ä»€ä¹ˆã€‚
>
> æ¨¡å‹æ˜¯ç”±æœºå™¨å­¦ä¹ ï¼ˆæ·±åº¦å­¦ä¹ ï¼‰æ¡†æ¶ç”Ÿæˆçš„ä¸€ç§åˆ†ç±»è§„åˆ™ï¼ˆç¥ç»ç½‘ç»œæ¨¡å‹ï¼‰ï¼Œå¸¸ç”¨çš„æ¡†æ¶æœ‰TensorFlow / PyTorch / Caffe ç­‰
>
> å®ƒä¸ä»…å¯ä»¥ç”Ÿæˆäººè„¸æ¨¡å‹ï¼Œè¿˜å¯ä»¥ç”ŸæˆğŸ±ğŸ±ğŸ¶ğŸ¶ ç­‰äº‹ä»¶ä¸‡ç‰©ï¼Œå›¾åƒåˆ†ç±»è¿˜åªæ˜¯å®ƒçš„å†°å±±ä¸€è§’ã€‚
>
> æ–‡æœ¬æ¶æ„æ£€æµ‹ / è¯­éŸ³è¯†åˆ« / è¯­ä¹‰åˆ†å‰² / äººä½“å§¿åŠ¿æ£€æµ‹ ç­‰ç­‰ã€‚å‘å¾ˆå¤§

## Demoä»£ç 

```html
<!DOCTYPE html>
<html>
<head>
<meta charset="utf-8">
<title>Hello OpenCV.js</title>
<style>
  .img_dectect, .video_dectect{
    display: flex;
  }
  .caption {
    text-align: center;
    border: 2px solid rgb(6, 155, 193);
    border-radius: 10px;
  }
</style>
</head>
<body>
<h2>Hello OpenCV.js</h2>
<p id="status">OpenCV.js è¯»å–ä¸­...</p>
<div>
  <h1>å›¾ç‰‡äººè„¸è¯†åˆ«</h1>
  <div><input type="file" id="imgInput" name="file" accept="image/*"> è¯·ä¸Šä¼ éœ€è¦è¯†åˆ«çš„å›¾ç‰‡</div>
  <button id="imgDectectButton" disabled>æ­£åœ¨è¯»å–OpenCV...</button>
  <div class="img_dectect">
    <div class="caption"><p>å›¾ç‰‡è¾“å…¥</p> <canvas id="imgCanvasInput" width="640"  height="480"></canvas></div>
    <div class="caption"><p>è¾“å‡ºè¯†åˆ«</p> <canvas id="imgCanvasOutput" width="640"  height="480"></canvas></div>
  </div>

  <h1>è§†é¢‘äººè„¸è¯†åˆ«</h1>
  <button id="videoDectectButton" disabled>æ­£åœ¨è¯»å–OpenCV...</button>
  <div class="video_dectect">
    <div class="caption">è§†é¢‘è¾“å…¥<video id="videoInput"  width="640"  height="480"></video></div>
    <div class="caption">è§†é¢‘è¾“å‡º<canvas id="canvasOutput" width="640"  height="480" ></canvas></div>
    <div class="caption">è§†é¢‘ä¸­é—´çŠ¶æ€è¾“å‡º<canvas id="canvasOutput2"></canvas></div>
  </div>


</div>
<script type="text/javascript">

//  ----------------------- å›¾ç‰‡äººè„¸è¯†åˆ« ----------------------
let imgDectectButton = document.getElementById('imgDectectButton');
imgDectectButton.addEventListener('click', startImgDectect);
let inputElement = document.getElementById('imgInput');
let imgCanvasInput = document.getElementById('imgCanvasInput');
let imgCanvasOutput = document.getElementById('imgCanvasOutput');
inputElement.addEventListener('change', (e) => {
    let files = e.target.files;
    if (files.length > 0) {
        let imgUrl = URL.createObjectURL(files[0]);
        let ctx = imgCanvasInput.getContext('2d');
        let img = new Image();
        img.crossOrigin = 'anonymous';
        img.onload = function() {
            imgCanvasInput.width = img.width;
            imgCanvasInput.height = img.height;
            imgCanvasOutput.width = img.width;
            imgCanvasOutput.height = img.height;
            ctx.drawImage(img, 0, 0, img.width, img.height);
        };
        img.src = imgUrl;
    }
}, false);

function startImgDectect () {
  let src = new cv.imread('imgCanvasInput');  // è¯»å–canvaså†…å›¾ç‰‡ æ”¾å…¥å®¹å™¨
  let gray = new cv.Mat();
  cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY, 0);
  let classifier = new cv.CascadeClassifier(); // çº§è” åˆ†ç±»å™¨
  classifier.load('face.xml'); // åŠ è½½è®­ç»ƒæ¨¡å‹
  let faces = new cv.RectVector();
  classifier.detectMultiScale(gray, faces, 1.1, 3, 0); // ä¾¦æµ‹è„¸éƒ¨
  for (let i = 0; i < faces.size(); ++i) {
      let roiGray = gray.roi(faces.get(i));
      let roiSrc = src.roi(faces.get(i));
      let point1 = new cv.Point(faces.get(i).x, faces.get(i).y);
      let point2 = new cv.Point(faces.get(i).x + faces.get(i).width,
                                faces.get(i).y + faces.get(i).height);
      cv.rectangle(src, point1, point2, [255, 0, 0, 255]);
  }
  
  // ç»˜åˆ¶åˆ°canvas
  cv.imshow('imgCanvasOutput', src);

  // æ¸…é™¤ç¼“å­˜
  src.delete();
  gray.delete();
  classifier.delete();
}
//  ----------------------- å›¾ç‰‡äººè„¸è¯†åˆ« ----------------------

//  ----------------------- è§†é¢‘äººè„¸è¯†åˆ« ----------------------
let videoDectectButton = document.getElementById('videoDectectButton');
videoDectectButton.addEventListener('click', startVideo);
let video = document.getElementById('videoInput');

function startVideo() {
  let src = new cv.Mat(video.height, video.width, cv.CV_8UC4); // å›¾åƒå®¹å™¨ 8ä½ 4é€šé“
  let gray = new cv.Mat();  // ç°åº¦å›¾å®¹å™¨
  let cap = new cv.VideoCapture(video); // è§†é¢‘é‡‡é›†å™¨
  let classifier = new cv.CascadeClassifier(); // çº§è” åˆ†ç±»å™¨
  classifier.load('face.xml'); // åŠ è½½è®­ç»ƒæ¨¡å‹

  const FPS = 30;
  function processVideo() {
    let begin = Date.now();
    // æˆªå–ä¸€å¸§å›¾åƒ
    cap.read(src);

    // è½¬æ¢ä¸ºç°åº¦å›¾
    cv.cvtColor(src, gray, cv.COLOR_RGBA2GRAY);

    
    let downSampled = new cv.Mat();
    cv.pyrDown(gray, downSampled); // æŠŠå›¾ç‰‡å˜å°ç‚¹ ä»¥å‡å°‘ä¾¦æµ‹æ—¶é—´
    cv.pyrDown(downSampled, downSampled);

    // ä¾¦æµ‹è„¸éƒ¨
    let faces = new cv.RectVector();
    classifier.detectMultiScale(downSampled, faces); // ä¾¦æµ‹è„¸éƒ¨

    // ç»˜åˆ¶è¾¹æ¡†
    let size = downSampled.size();
    let xRatio = video.width / size.width;
    let yRatio = video.height / size.height;
    for (let i = 0; i < faces.size(); ++i) {
        let face = faces.get(i);
        let point1 = new cv.Point(face.x * xRatio, face.y * yRatio);
        let point2 = new cv.Point((face.x + face.width) * xRatio, (face.y + face.height) * xRatio);
        cv.rectangle(src, point1, point2, [255, 0, 0, 255])
    }

    // ç»˜åˆ¶æœ€ç»ˆç»“æœ
    cv.imshow('canvasOutput', src);
    cv.imshow('canvasOutput2', downSampled);

    // é‡Šæ”¾å†…å­˜
    downSampled.delete();
    faces.delete();

    let delay = 1000/FPS - (Date.now() - begin);
    setTimeout(processVideo, delay);
  };
  setTimeout(processVideo, 0);
}
//  ----------------------- è§†é¢‘äººè„¸è¯†åˆ« ----------------------

// è¯»å–æ‘„åƒå¤´api è¾“å‡ºåˆ°canvas
let constraints = { audio: false, video: { width: video.width, height: video.height } }; 
navigator.mediaDevices.getUserMedia(constraints)
.then(function(mediaStream) {
  let video = document.getElementById('videoInput');
  video.srcObject = mediaStream;
  video.onloadedmetadata = function(e) {
    video.play();
  };
})
.catch(function(err) { console.log(err.name + ": " + err.message); });

// ------------------------- åˆå§‹åŒ– ----------------------
// è¯»å–è®­ç»ƒæ¨¡å‹ äººè„¸è¯†åˆ« éœ€è¦ç”¨
function loadXmlData() {
  let request = new XMLHttpRequest();
  request.open('GET', 'face.xml');
  request.responseType = 'arraybuffer';
  request.onload = function(ev) {
      if (request.readyState === 4) {
          if (request.status === 200) {
              let data = new Uint8Array(request.response);
              cv.FS_createDataFile('/', 'face.xml', data, true, false, false);
              imgDectectButton.removeAttribute('disabled');
              videoDectectButton.removeAttribute('disabled');
              document.getElementById('status').innerHTML = 'OpenCV.js å·²å°±ç»ª.';
              imgDectectButton.innerHTML = 'å¼€å§‹è¯†åˆ«';
              videoDectectButton.innerHTML = 'å¼€å§‹è¯†åˆ«';
          }
      }
  };
  request.send();
}

// ç­‰å¾… opencv è¯»å–ç³»ç»Ÿä¿¡æ¯
async function onOpenCvReady() {
  if (cv.getBuildInformation) {
      console.log(cv.getBuildInformation());
      loadXmlData();
  } else {
    if (cv instanceof Promise) {
      cv = await cv;
      console.log(cv.getBuildInformation());
      loadXmlData();
    } else {
      cv.onRuntimeInitialized = () => {
        console.log(cv.getBuildInformation());
        loadXmlData();
      }
    }
  }
}
// ------------------------- åˆå§‹åŒ– ----------------------
</script>
<script async src="opencv.js" onload="onOpenCvReady();" type="text/javascript"></script>
</body>
</html>
```





## æ­å»º Demo è¿‡ç¨‹ä¸­è¸©çš„å‘

1. éœ€è¦è¿è¡Œåœ¨æœåŠ¡å™¨ç¯å¢ƒä¸‹ï¼Œä¸ç„¶åœ¨è·å–æ¨¡å‹xmlæ–‡ä»¶æ—¶ä¼šäº§ç”Ÿè·¨åŸŸè¯·æ±‚ã€‚å¯ä»¥ npm install http-server --save å®‰è£…ä¸€ä¸ªæœ¬åœ°ç®€æ˜“çš„æœåŠ¡å™¨ï¼Œæ–¹ä¾¿å¼€å‘ã€‚
2. ä¸Šä¼ åˆ°æœåŠ¡å™¨ç«¯ï¼Œéœ€è¦æœåŠ¡å™¨ç«¯éƒ¨ç½² https ä¸ç„¶æµè§ˆå™¨ä¸ä¼šç»™è¯¥ç½‘ç«™è¯»å–æ‘„åƒå¤´çš„æƒé™
3. åœ¨ä¾¦æµ‹è„¸éƒ¨ä»¥åŠè¾“å‡ºè¿‡ç¨‹ä¸­ canvas çš„æ¡†é«˜éœ€è¦ä¸ mat çš„å®½é«˜ä¸€è‡´ï¼Œä¸ç„¶ä¼šbug